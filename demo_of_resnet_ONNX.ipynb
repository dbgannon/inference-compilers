{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some standard imports\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.onnx\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import netron\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 1.   The cost of doing a convolution\n",
    "this is the detail in the paper where we do the loop restructuring to improve the locality of the computation and then reduce the computation to low-level primatives.   \n",
    "\n",
    "The forumla below is for a comvolution.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Output(i, k, j) ~=~ \\sum^3_{t=1} \\sum^3_{u=1}\\sum^3_{v=1}W(i,t, u,v) \\cdot Input(t,k+u-2,j+v-2) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some of the sample parameters used in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cout =4\n",
    "Cin = 64\n",
    "width = 10\n",
    "height = 10\n",
    "Output = torch.zeros(Cout, width, height)\n",
    "Image = torch.zeros(Cin,width, height)+2\n",
    "Input = torch.zeros(Cin, width+2, height+2)+1\n",
    "Input[:,1:width+1, 1:height+1]= Image[:, 0:width, 0:height]\n",
    "W = torch.zeros(Cout, Cin, 3,3)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.816189765930176\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for i in range(0,Cout):\n",
    "    for k in range(0, width):\n",
    "        for j in range(0, height):\n",
    "            for t in range(0,Cin):\n",
    "                for u in range(0,3):\n",
    "                    for v in range(0,3):\n",
    "                        Output[i,k,j]+= W[i,t,u,v]*Input[t, k+u, j+v]\n",
    "elapse = time.time()-t0\n",
    "print(elapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first transformation pulls out the inner three looks and does he sum locally rather than writing it back to memory in the array each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.252971172332764\n"
     ]
    }
   ],
   "source": [
    "def kernel(W,Input, i, k, j):\n",
    "    Outv = 0.0\n",
    "    for t in range(0,Cin):\n",
    "        for u in range(0,3):\n",
    "            for v in range(0,3):\n",
    "                Outv += W[i,t,u,v]*Input[t, k+u, j+v] \n",
    "    return Outv\n",
    "t0 =time.time()\n",
    "for i in range(0,Cout):\n",
    "    for k in range(0, width):\n",
    "        for j in range(0, height):\n",
    "                Output[i,k,j] = kernel(W,Input,i,k,j)\n",
    "\n",
    "elapse = time.time()-t0\n",
    "print(elapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "second transformation.  in kernel function move the t loop inside and replace it with the dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10005521774291992\n"
     ]
    }
   ],
   "source": [
    "def kernel2(W,Input, i, k, j):\n",
    "    Outv = 0.0\n",
    "    for u in range(0,3):\n",
    "        for v in range(0,3):\n",
    "            Outv += torch.dot(W[i,:,u,v],Input[:, k+u, j+v]) \n",
    "    return Outv\n",
    "t0 = time.time()\n",
    "for i in range(0,Cout):\n",
    "    for k in range(0, width):\n",
    "        for j in range(0, height):\n",
    "                Output[i,k,j] = kernel2(W,Input,i,k,j)\n",
    "elapse = time.time()-t0\n",
    "print(elapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now recognize the function is just a sum of pointwise multiplies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02820301055908203\n"
     ]
    }
   ],
   "source": [
    "def kernel3(W,Input):\n",
    "    return torch.sum(W*Input) \n",
    "\n",
    "t0 = time.time()\n",
    "for i in range(0,Cout):\n",
    "    for k in range(0, width):\n",
    "        for j in range(0, height):\n",
    "                Output[i,k,j] = kernel3(W[i,:,:,:],Input[i,k:k+3, j:j+3])\n",
    "\n",
    "elapse = time.time()-t0\n",
    "\n",
    "print(elapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do it really fast.   10 invocations of the Conv2d function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007052421569824219\n"
     ]
    }
   ],
   "source": [
    "q = torch.nn.Conv2d(Cin,Cout,3, stride=1, padding=1, dilation=1, groups=1, bias=False, padding_mode='zeros')\n",
    "Im= torch.zeros(1,Cin,width, height)\n",
    "\n",
    "t0 = time.time()\n",
    "outl = []\n",
    "for i in range(0,10):\n",
    "    outv = q(Im)\n",
    "    outl.append(outv)\n",
    "    outv=outv+1\n",
    "\n",
    "elapse = time.time()-t0\n",
    "print(elapse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dt\n",
    "import torch\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a demonstration of generating ONNX from a simplifed version of a residual network.\n",
    "\n",
    "see https://towardsdatascience.com/residual-network-implementing-resnet-a7da63c7b278\n",
    "for a more complete version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, inchannel, outchannel, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "                        nn.BatchNorm2d(outchannel),\n",
    "                        )\n",
    "        self.conv2  = nn.Sequential(\n",
    "                        nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                        nn.BatchNorm2d(outchannel)\n",
    "                    )\n",
    "        self.skip = nn.Sequential()\n",
    "        if stride != 1 or inchannel != self.expansion * outchannel:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, self.expansion * outchannel, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * outchannel)\n",
    "            )\n",
    "\n",
    "    def forward(self, X):\n",
    "        out = F.relu(self.conv1(X))\n",
    "        out = self.conv2(out)\n",
    "        out += self.skip(X)\n",
    "        out = F.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, ResidualBlock, num_classes):\n",
    "        super(Model, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.layer1 = self.make_layer(ResidualBlock, 64,  2, stride=1)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride=2)\n",
    "        self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride=2)\n",
    "        self.fc = nn.Linear(512*ResidualBlock.expansion, num_classes)\n",
    "\n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)   \n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            self.inchannel = channels * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        i = int(out.size()[3])\n",
    "        out = F.avg_pool2d(out, i)\n",
    "        out = torch.flatten(out,1 )\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Sequential()\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = Model(ResidualBlock,num_classes = 2)\n",
    "resnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "inframe = torch.zeros(1,3,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0045, -0.0049]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet(inframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input : Float(1, 3, 32, 32),\n",
      "      %conv1.0.weight : Float(64, 3, 7, 7),\n",
      "      %conv1.1.weight : Float(64),\n",
      "      %conv1.1.bias : Float(64),\n",
      "      %conv1.1.running_mean : Float(64),\n",
      "      %conv1.1.running_var : Float(64),\n",
      "      %conv1.1.num_batches_tracked : Long(),\n",
      "      %layer1.0.conv1.0.weight : Float(64, 64, 3, 3),\n",
      "      %layer1.0.conv1.1.weight : Float(64),\n",
      "      %layer1.0.conv1.1.bias : Float(64),\n",
      "      %layer1.0.conv1.1.running_mean : Float(64),\n",
      "      %layer1.0.conv1.1.running_var : Float(64),\n",
      "      %layer1.0.conv1.1.num_batches_tracked : Long(),\n",
      "      %layer1.0.conv2.0.weight : Float(64, 64, 3, 3),\n",
      "      %layer1.0.conv2.1.weight : Float(64),\n",
      "      %layer1.0.conv2.1.bias : Float(64),\n",
      "      %layer1.0.conv2.1.running_mean : Float(64),\n",
      "      %layer1.0.conv2.1.running_var : Float(64),\n",
      "      %layer1.0.conv2.1.num_batches_tracked : Long(),\n",
      "      %layer1.1.conv1.0.weight : Float(64, 64, 3, 3),\n",
      "      %layer1.1.conv1.1.weight : Float(64),\n",
      "      %layer1.1.conv1.1.bias : Float(64),\n",
      "      %layer1.1.conv1.1.running_mean : Float(64),\n",
      "      %layer1.1.conv1.1.running_var : Float(64),\n",
      "      %layer1.1.conv1.1.num_batches_tracked : Long(),\n",
      "      %layer1.1.conv2.0.weight : Float(64, 64, 3, 3),\n",
      "      %layer1.1.conv2.1.weight : Float(64),\n",
      "      %layer1.1.conv2.1.bias : Float(64),\n",
      "      %layer1.1.conv2.1.running_mean : Float(64),\n",
      "      %layer1.1.conv2.1.running_var : Float(64),\n",
      "      %layer1.1.conv2.1.num_batches_tracked : Long(),\n",
      "      %layer2.0.conv1.0.weight : Float(128, 64, 3, 3),\n",
      "      %layer2.0.conv1.1.weight : Float(128),\n",
      "      %layer2.0.conv1.1.bias : Float(128),\n",
      "      %layer2.0.conv1.1.running_mean : Float(128),\n",
      "      %layer2.0.conv1.1.running_var : Float(128),\n",
      "      %layer2.0.conv1.1.num_batches_tracked : Long(),\n",
      "      %layer2.0.conv2.0.weight : Float(128, 128, 3, 3),\n",
      "      %layer2.0.conv2.1.weight : Float(128),\n",
      "      %layer2.0.conv2.1.bias : Float(128),\n",
      "      %layer2.0.conv2.1.running_mean : Float(128),\n",
      "      %layer2.0.conv2.1.running_var : Float(128),\n",
      "      %layer2.0.conv2.1.num_batches_tracked : Long(),\n",
      "      %layer2.0.skip.0.weight : Float(128, 64, 1, 1),\n",
      "      %layer2.0.skip.1.weight : Float(128),\n",
      "      %layer2.0.skip.1.bias : Float(128),\n",
      "      %layer2.0.skip.1.running_mean : Float(128),\n",
      "      %layer2.0.skip.1.running_var : Float(128),\n",
      "      %layer2.0.skip.1.num_batches_tracked : Long(),\n",
      "      %layer2.1.conv1.0.weight : Float(128, 128, 3, 3),\n",
      "      %layer2.1.conv1.1.weight : Float(128),\n",
      "      %layer2.1.conv1.1.bias : Float(128),\n",
      "      %layer2.1.conv1.1.running_mean : Float(128),\n",
      "      %layer2.1.conv1.1.running_var : Float(128),\n",
      "      %layer2.1.conv1.1.num_batches_tracked : Long(),\n",
      "      %layer2.1.conv2.0.weight : Float(128, 128, 3, 3),\n",
      "      %layer2.1.conv2.1.weight : Float(128),\n",
      "      %layer2.1.conv2.1.bias : Float(128),\n",
      "      %layer2.1.conv2.1.running_mean : Float(128),\n",
      "      %layer2.1.conv2.1.running_var : Float(128),\n",
      "      %layer2.1.conv2.1.num_batches_tracked : Long(),\n",
      "      %layer3.0.conv1.0.weight : Float(256, 128, 3, 3),\n",
      "      %layer3.0.conv1.1.weight : Float(256),\n",
      "      %layer3.0.conv1.1.bias : Float(256),\n",
      "      %layer3.0.conv1.1.running_mean : Float(256),\n",
      "      %layer3.0.conv1.1.running_var : Float(256),\n",
      "      %layer3.0.conv1.1.num_batches_tracked : Long(),\n",
      "      %layer3.0.conv2.0.weight : Float(256, 256, 3, 3),\n",
      "      %layer3.0.conv2.1.weight : Float(256),\n",
      "      %layer3.0.conv2.1.bias : Float(256),\n",
      "      %layer3.0.conv2.1.running_mean : Float(256),\n",
      "      %layer3.0.conv2.1.running_var : Float(256),\n",
      "      %layer3.0.conv2.1.num_batches_tracked : Long(),\n",
      "      %layer3.0.skip.0.weight : Float(256, 128, 1, 1),\n",
      "      %layer3.0.skip.1.weight : Float(256),\n",
      "      %layer3.0.skip.1.bias : Float(256),\n",
      "      %layer3.0.skip.1.running_mean : Float(256),\n",
      "      %layer3.0.skip.1.running_var : Float(256),\n",
      "      %layer3.0.skip.1.num_batches_tracked : Long(),\n",
      "      %layer3.1.conv1.0.weight : Float(256, 256, 3, 3),\n",
      "      %layer3.1.conv1.1.weight : Float(256),\n",
      "      %layer3.1.conv1.1.bias : Float(256),\n",
      "      %layer3.1.conv1.1.running_mean : Float(256),\n",
      "      %layer3.1.conv1.1.running_var : Float(256),\n",
      "      %layer3.1.conv1.1.num_batches_tracked : Long(),\n",
      "      %layer3.1.conv2.0.weight : Float(256, 256, 3, 3),\n",
      "      %layer3.1.conv2.1.weight : Float(256),\n",
      "      %layer3.1.conv2.1.bias : Float(256),\n",
      "      %layer3.1.conv2.1.running_mean : Float(256),\n",
      "      %layer3.1.conv2.1.running_var : Float(256),\n",
      "      %layer3.1.conv2.1.num_batches_tracked : Long(),\n",
      "      %layer4.0.conv1.0.weight : Float(512, 256, 3, 3),\n",
      "      %layer4.0.conv1.1.weight : Float(512),\n",
      "      %layer4.0.conv1.1.bias : Float(512),\n",
      "      %layer4.0.conv1.1.running_mean : Float(512),\n",
      "      %layer4.0.conv1.1.running_var : Float(512),\n",
      "      %layer4.0.conv1.1.num_batches_tracked : Long(),\n",
      "      %layer4.0.conv2.0.weight : Float(512, 512, 3, 3),\n",
      "      %layer4.0.conv2.1.weight : Float(512),\n",
      "      %layer4.0.conv2.1.bias : Float(512),\n",
      "      %layer4.0.conv2.1.running_mean : Float(512),\n",
      "      %layer4.0.conv2.1.running_var : Float(512),\n",
      "      %layer4.0.conv2.1.num_batches_tracked : Long(),\n",
      "      %layer4.0.skip.0.weight : Float(512, 256, 1, 1),\n",
      "      %layer4.0.skip.1.weight : Float(512),\n",
      "      %layer4.0.skip.1.bias : Float(512),\n",
      "      %layer4.0.skip.1.running_mean : Float(512),\n",
      "      %layer4.0.skip.1.running_var : Float(512),\n",
      "      %layer4.0.skip.1.num_batches_tracked : Long(),\n",
      "      %layer4.1.conv1.0.weight : Float(512, 512, 3, 3),\n",
      "      %layer4.1.conv1.1.weight : Float(512),\n",
      "      %layer4.1.conv1.1.bias : Float(512),\n",
      "      %layer4.1.conv1.1.running_mean : Float(512),\n",
      "      %layer4.1.conv1.1.running_var : Float(512),\n",
      "      %layer4.1.conv1.1.num_batches_tracked : Long(),\n",
      "      %layer4.1.conv2.0.weight : Float(512, 512, 3, 3),\n",
      "      %layer4.1.conv2.1.weight : Float(512),\n",
      "      %layer4.1.conv2.1.bias : Float(512),\n",
      "      %layer4.1.conv2.1.running_mean : Float(512),\n",
      "      %layer4.1.conv2.1.running_var : Float(512),\n",
      "      %layer4.1.conv2.1.num_batches_tracked : Long(),\n",
      "      %fc.weight : Float(2, 512),\n",
      "      %fc.bias : Float(2)):\n",
      "  %123 : Float(1, 64, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[3, 3, 3, 3], strides=[1, 1]](%input, %conv1.0.weight), scope: Model/Sequential[conv1]/Conv2d[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:342:0\n",
      "  %124 : Float(1, 64, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%123, %conv1.1.weight, %conv1.1.bias, %conv1.1.running_mean, %conv1.1.running_var), scope: Model/Sequential[conv1]/BatchNorm2d[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1670:0\n",
      "  %125 : Float(1, 64, 32, 32) = onnx::Relu(%124), scope: Model # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:914:0\n",
      "  %126 : Float(1, 64, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%125, %layer1.0.conv1.0.weight), scope: Model/Sequential[layer1]/ResidualBlock[0]/Sequential[conv1]/Conv2d[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:342:0\n",
      "  %127 : Float(1, 64, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%126, %layer1.0.conv1.1.weight, %layer1.0.conv1.1.bias, %layer1.0.conv1.1.running_mean, %layer1.0.conv1.1.running_var), scope: Model/Sequential[layer1]/ResidualBlock[0]/Sequential[conv1]/BatchNorm2d[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1670:0\n",
      "  %128 : Float(1, 64, 32, 32) = onnx::Relu(%127), scope: Model/Sequential[layer1]/ResidualBlock[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:914:0\n",
      "  %129 : Float(1, 64, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%128, %layer1.0.conv2.0.weight), scope: Model/Sequential[layer1]/ResidualBlock[0]/Sequential[conv2]/Conv2d[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:342:0\n",
      "  %130 : Float(1, 64, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%129, %layer1.0.conv2.1.weight, %layer1.0.conv2.1.bias, %layer1.0.conv2.1.running_mean, %layer1.0.conv2.1.running_var), scope: Model/Sequential[layer1]/ResidualBlock[0]/Sequential[conv2]/BatchNorm2d[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1670:0\n",
      "  %131 : Float(1, 64, 32, 32) = onnx::Add(%130, %125), scope: Model/Sequential[layer1]/ResidualBlock[0] # <ipython-input-24-a6d437362805>:23:0\n",
      "  %132 : Float(1, 64, 32, 32) = onnx::Relu(%131), scope: Model/Sequential[layer1]/ResidualBlock[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:914:0\n",
      "  %133 : Float(1, 64, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%132, %layer1.1.conv1.0.weight), scope: Model/Sequential[layer1]/ResidualBlock[1]/Sequential[conv1]/Conv2d[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:342:0\n",
      "  %134 : Float(1, 64, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%133, %layer1.1.conv1.1.weight, %layer1.1.conv1.1.bias, %layer1.1.conv1.1.running_mean, %layer1.1.conv1.1.running_var), scope: Model/Sequential[layer1]/ResidualBlock[1]/Sequential[conv1]/BatchNorm2d[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1670:0\n",
      "  %135 : Float(1, 64, 32, 32) = onnx::Relu(%134), scope: Model/Sequential[layer1]/ResidualBlock[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:914:0\n",
      "  %136 : Float(1, 64, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%135, %layer1.1.conv2.0.weight), scope: Model/Sequential[layer1]/ResidualBlock[1]/Sequential[conv2]/Conv2d[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:342:0\n",
      "  %137 : Float(1, 64, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%136, %layer1.1.conv2.1.weight, %layer1.1.conv2.1.bias, %layer1.1.conv2.1.running_mean, %layer1.1.conv2.1.running_var), scope: Model/Sequential[layer1]/ResidualBlock[1]/Sequential[conv2]/BatchNorm2d[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1670:0\n",
      "  %138 : Float(1, 64, 32, 32) = onnx::Add(%137, %132), scope: Model/Sequential[layer1]/ResidualBlock[1] # <ipython-input-24-a6d437362805>:23:0\n",
      "  %139 : Float(1, 64, 32, 32) = onnx::Relu(%138), scope: Model/Sequential[layer1]/ResidualBlock[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:914:0\n",
      "  %140 : Float(1, 128, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%139, %layer2.0.conv1.0.weight), scope: Model/Sequential[layer2]/ResidualBlock[0]/Sequential[conv1]/Conv2d[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:342:0\n",
      "  %141 : Float(1, 128, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%140, %layer2.0.conv1.1.weight, %layer2.0.conv1.1.bias, %layer2.0.conv1.1.running_mean, %layer2.0.conv1.1.running_var), scope: Model/Sequential[layer2]/ResidualBlock[0]/Sequential[conv1]/BatchNorm2d[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1670:0\n",
      "  %142 : Float(1, 128, 16, 16) = onnx::Relu(%141), scope: Model/Sequential[layer2]/ResidualBlock[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:914:0\n",
      "  %143 : Float(1, 128, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%142, %layer2.0.conv2.0.weight), scope: Model/Sequential[layer2]/ResidualBlock[0]/Sequential[conv2]/Conv2d[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:342:0\n",
      "  %144 : Float(1, 128, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%143, %layer2.0.conv2.1.weight, %layer2.0.conv2.1.bias, %layer2.0.conv2.1.running_mean, %layer2.0.conv2.1.running_var), scope: Model/Sequential[layer2]/ResidualBlock[0]/Sequential[conv2]/BatchNorm2d[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1670:0\n",
      "  %145 : Float(1, 128, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%139, %layer2.0.skip.0.weight), scope: Model/Sequential[layer2]/ResidualBlock[0]/Sequential[skip]/Conv2d[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:342:0\n",
      "  %146 : Float(1, 128, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%145, %layer2.0.skip.1.weight, %layer2.0.skip.1.bias, %layer2.0.skip.1.running_mean, %layer2.0.skip.1.running_var), scope: Model/Sequential[layer2]/ResidualBlock[0]/Sequential[skip]/BatchNorm2d[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1670:0\n",
      "  %147 : Float(1, 128, 16, 16) = onnx::Add(%144, %146), scope: Model/Sequential[layer2]/ResidualBlock[0] # <ipython-input-24-a6d437362805>:23:0\n",
      "  %148 : Float(1, 128, 16, 16) = onnx::Relu(%147), scope: Model/Sequential[layer2]/ResidualBlock[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:914:0\n",
      "  %149 : Float(1, 128, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%148, %layer2.1.conv1.0.weight), scope: Model/Sequential[layer2]/ResidualBlock[1]/Sequential[conv1]/Conv2d[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:342:0\n",
      "  %150 : Float(1, 128, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%149, %layer2.1.conv1.1.weight, %layer2.1.conv1.1.bias, %layer2.1.conv1.1.running_mean, %layer2.1.conv1.1.running_var), scope: Model/Sequential[layer2]/ResidualBlock[1]/Sequential[conv1]/BatchNorm2d[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1670:0\n",
      "  %151 : Float(1, 128, 16, 16) = onnx::Relu(%150), scope: Model/Sequential[layer2]/ResidualBlock[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:914:0\n",
      "  %152 : Float(1, 128, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%151, %layer2.1.conv2.0.weight), scope: Model/Sequential[layer2]/ResidualBlock[1]/Sequential[conv2]/Conv2d[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:342:0\n",
      "  %153 : Float(1, 128, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%152, %layer2.1.conv2.1.weight, %layer2.1.conv2.1.bias, %layer2.1.conv2.1.running_mean, %layer2.1.conv2.1.running_var), scope: Model/Sequential[layer2]/ResidualBlock[1]/Sequential[conv2]/BatchNorm2d[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1670:0\n",
      "  %154 : Float(1, 128, 16, 16) = onnx::Add(%153, %148), scope: Model/Sequential[layer2]/ResidualBlock[1] # <ipython-input-24-a6d437362805>:23:0\n",
      "  %155 : Float(1, 128, 16, 16) = onnx::Relu(%154), scope: Model/Sequential[layer2]/ResidualBlock[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:914:0\n",
      "  %156 : Float(1, 256, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%155, %layer3.0.conv1.0.weight), scope: Model/Sequential[layer3]/ResidualBlock[0]/Sequential[conv1]/Conv2d[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:342:0\n",
      "  %157 : Float(1, 256, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%156, %layer3.0.conv1.1.weight, %layer3.0.conv1.1.bias, %layer3.0.conv1.1.running_mean, %layer3.0.conv1.1.running_var), scope: Model/Sequential[layer3]/ResidualBlock[0]/Sequential[conv1]/BatchNorm2d[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1670:0\n",
      "  %158 : Float(1, 256, 8, 8) = onnx::Relu(%157), scope: Model/Sequential[layer3]/ResidualBlock[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:914:0\n",
      "  %159 : Float(1, 256, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%158, %layer3.0.conv2.0.weight), scope: Model/Sequential[layer3]/ResidualBlock[0]/Sequential[conv2]/Conv2d[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:342:0\n",
      "  %160 : Float(1, 256, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%159, %layer3.0.conv2.1.weight, %layer3.0.conv2.1.bias, %layer3.0.conv2.1.running_mean, %layer3.0.conv2.1.running_var), scope: Model/Sequential[layer3]/ResidualBlock[0]/Sequential[conv2]/BatchNorm2d[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1670:0\n",
      "  %161 : Float(1, 256, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%155, %layer3.0.skip.0.weight), scope: Model/Sequential[layer3]/ResidualBlock[0]/Sequential[skip]/Conv2d[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:342:0\n",
      "  %162 : Float(1, 256, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%161, %layer3.0.skip.1.weight, %layer3.0.skip.1.bias, %layer3.0.skip.1.running_mean, %layer3.0.skip.1.running_var), scope: Model/Sequential[layer3]/ResidualBlock[0]/Sequential[skip]/BatchNorm2d[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1670:0\n",
      "  %163 : Float(1, 256, 8, 8) = onnx::Add(%160, %162), scope: Model/Sequential[layer3]/ResidualBlock[0] # <ipython-input-24-a6d437362805>:23:0\n",
      "  %164 : Float(1, 256, 8, 8) = onnx::Relu(%163), scope: Model/Sequential[layer3]/ResidualBlock[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:914:0\n",
      "  %165 : Float(1, 256, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%164, %layer3.1.conv1.0.weight), scope: Model/Sequential[layer3]/ResidualBlock[1]/Sequential[conv1]/Conv2d[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:342:0\n",
      "  %166 : Float(1, 256, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%165, %layer3.1.conv1.1.weight, %layer3.1.conv1.1.bias, %layer3.1.conv1.1.running_mean, %layer3.1.conv1.1.running_var), scope: Model/Sequential[layer3]/ResidualBlock[1]/Sequential[conv1]/BatchNorm2d[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1670:0\n",
      "  %167 : Float(1, 256, 8, 8) = onnx::Relu(%166), scope: Model/Sequential[layer3]/ResidualBlock[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:914:0\n",
      "  %168 : Float(1, 256, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%167, %layer3.1.conv2.0.weight), scope: Model/Sequential[layer3]/ResidualBlock[1]/Sequential[conv2]/Conv2d[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:342:0\n",
      "  %169 : Float(1, 256, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%168, %layer3.1.conv2.1.weight, %layer3.1.conv2.1.bias, %layer3.1.conv2.1.running_mean, %layer3.1.conv2.1.running_var), scope: Model/Sequential[layer3]/ResidualBlock[1]/Sequential[conv2]/BatchNorm2d[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1670:0\n",
      "  %170 : Float(1, 256, 8, 8) = onnx::Add(%169, %164), scope: Model/Sequential[layer3]/ResidualBlock[1] # <ipython-input-24-a6d437362805>:23:0\n",
      "  %171 : Float(1, 256, 8, 8) = onnx::Relu(%170), scope: Model/Sequential[layer3]/ResidualBlock[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:914:0\n",
      "  %172 : Float(1, 512, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%171, %layer4.0.conv1.0.weight), scope: Model/Sequential[layer4]/ResidualBlock[0]/Sequential[conv1]/Conv2d[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:342:0\n",
      "  %173 : Float(1, 512, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%172, %layer4.0.conv1.1.weight, %layer4.0.conv1.1.bias, %layer4.0.conv1.1.running_mean, %layer4.0.conv1.1.running_var), scope: Model/Sequential[layer4]/ResidualBlock[0]/Sequential[conv1]/BatchNorm2d[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1670:0\n",
      "  %174 : Float(1, 512, 4, 4) = onnx::Relu(%173), scope: Model/Sequential[layer4]/ResidualBlock[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:914:0\n",
      "  %175 : Float(1, 512, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%174, %layer4.0.conv2.0.weight), scope: Model/Sequential[layer4]/ResidualBlock[0]/Sequential[conv2]/Conv2d[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:342:0\n",
      "  %176 : Float(1, 512, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%175, %layer4.0.conv2.1.weight, %layer4.0.conv2.1.bias, %layer4.0.conv2.1.running_mean, %layer4.0.conv2.1.running_var), scope: Model/Sequential[layer4]/ResidualBlock[0]/Sequential[conv2]/BatchNorm2d[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1670:0\n",
      "  %177 : Float(1, 512, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%171, %layer4.0.skip.0.weight), scope: Model/Sequential[layer4]/ResidualBlock[0]/Sequential[skip]/Conv2d[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:342:0\n",
      "  %178 : Float(1, 512, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%177, %layer4.0.skip.1.weight, %layer4.0.skip.1.bias, %layer4.0.skip.1.running_mean, %layer4.0.skip.1.running_var), scope: Model/Sequential[layer4]/ResidualBlock[0]/Sequential[skip]/BatchNorm2d[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1670:0\n",
      "  %179 : Float(1, 512, 4, 4) = onnx::Add(%176, %178), scope: Model/Sequential[layer4]/ResidualBlock[0] # <ipython-input-24-a6d437362805>:23:0\n",
      "  %180 : Float(1, 512, 4, 4) = onnx::Relu(%179), scope: Model/Sequential[layer4]/ResidualBlock[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:914:0\n",
      "  %181 : Float(1, 512, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%180, %layer4.1.conv1.0.weight), scope: Model/Sequential[layer4]/ResidualBlock[1]/Sequential[conv1]/Conv2d[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:342:0\n",
      "  %182 : Float(1, 512, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%181, %layer4.1.conv1.1.weight, %layer4.1.conv1.1.bias, %layer4.1.conv1.1.running_mean, %layer4.1.conv1.1.running_var), scope: Model/Sequential[layer4]/ResidualBlock[1]/Sequential[conv1]/BatchNorm2d[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1670:0\n",
      "  %183 : Float(1, 512, 4, 4) = onnx::Relu(%182), scope: Model/Sequential[layer4]/ResidualBlock[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:914:0\n",
      "  %184 : Float(1, 512, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%183, %layer4.1.conv2.0.weight), scope: Model/Sequential[layer4]/ResidualBlock[1]/Sequential[conv2]/Conv2d[0] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:342:0\n",
      "  %185 : Float(1, 512, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%184, %layer4.1.conv2.1.weight, %layer4.1.conv2.1.bias, %layer4.1.conv2.1.running_mean, %layer4.1.conv2.1.running_var), scope: Model/Sequential[layer4]/ResidualBlock[1]/Sequential[conv2]/BatchNorm2d[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1670:0\n",
      "  %186 : Float(1, 512, 4, 4) = onnx::Add(%185, %180), scope: Model/Sequential[layer4]/ResidualBlock[1] # <ipython-input-24-a6d437362805>:23:0\n",
      "  %187 : Float(1, 512, 4, 4) = onnx::Relu(%186), scope: Model/Sequential[layer4]/ResidualBlock[1] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:914:0\n",
      "  %188 : Tensor = onnx::Pad[mode=\"constant\", pads=[0, 0, 0, 0, 0, 0, 0, 0], value=0](%187), scope: Model\n",
      "  %189 : Float(1, 512, 1, 1) = onnx::AveragePool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%188), scope: Model # <ipython-input-25-8ea530f6f7a1>:30:0\n",
      "  %190 : Float(1, 512) = onnx::Flatten[axis=1](%189), scope: Model # <ipython-input-25-8ea530f6f7a1>:31:0\n",
      "  %191 : Float(1, 2) = onnx::Gemm[alpha=1, beta=1, transB=1](%190, %fc.weight, %fc.bias), scope: Model/Linear[fc] # C:\\Users\\ganno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1370:0\n",
      "  return (%191)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(resnet,\n",
    "                  inframe,   \n",
    "                  \"resnet.onnx\",\n",
    "                  verbose=True,\n",
    "                  input_names = ['input']\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving './resnet.onnx' at http://localhost:8080\n"
     ]
    }
   ],
   "source": [
    "optimized_model_path = './resnet.onnx'\n",
    "netron.start(optimized_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
